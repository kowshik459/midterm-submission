{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8727f2ea-5d89-4037-ae3f-f0dd8b91a76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 10 imports successful ✅\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from day02_environment.trading_env import TradingEnv\n",
    "\n",
    "print(\"Day 10 imports successful ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4339d13e-d58c-4ae4-8688-06f5025209f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL model loaded ✅\n"
     ]
    }
   ],
   "source": [
    "# Load trained PPO model from Day 5\n",
    "model_path = \"../day05_sanity_check/ppo_trading_model\"\n",
    "\n",
    "model = PPO.load(model_path)\n",
    "print(\"RL model loaded ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "231d16b0-00f7-4890-baa6-86e904260d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_returns(equity_curve):\n",
    "    returns = np.diff(equity_curve) / equity_curve[:-1]\n",
    "    return returns\n",
    "\n",
    "def sharpe_ratio(returns, eps=1e-8):\n",
    "    return np.mean(returns) / (np.std(returns) + eps)\n",
    "\n",
    "def max_drawdown(equity_curve):\n",
    "    peak = equity_curve[0]\n",
    "    max_dd = 0.0\n",
    "    for value in equity_curve:\n",
    "        peak = max(peak, value)\n",
    "        dd = (peak - value) / peak\n",
    "        max_dd = max(max_dd, dd)\n",
    "    return max_dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da1cf564-8828-46d5-a86d-a3322b5387f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL Sharpe: 0.000\n",
      "RL Max Drawdown: 0.000\n"
     ]
    }
   ],
   "source": [
    "def run_rl_agent(env, model):\n",
    "    obs, _ = env.reset()\n",
    "    equity = [1.0]  # initial capital\n",
    "\n",
    "    done = False\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        equity.append(equity[-1] + reward)\n",
    "        done = terminated or truncated\n",
    "\n",
    "    return np.array(equity)\n",
    "\n",
    "\n",
    "env = TradingEnv(max_steps=1000)\n",
    "rl_equity = run_rl_agent(env, model)\n",
    "\n",
    "rl_returns = compute_returns(rl_equity)\n",
    "\n",
    "rl_sharpe = sharpe_ratio(rl_returns)\n",
    "rl_dd = max_drawdown(rl_equity)\n",
    "\n",
    "print(f\"RL Sharpe: {rl_sharpe:.3f}\")\n",
    "print(f\"RL Max Drawdown: {rl_dd:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddfd52ad-76e0-4376-99d1-c71c9320f69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buy & Hold Sharpe: 0.060\n",
      "Buy & Hold Max Drawdown: 489.948\n"
     ]
    }
   ],
   "source": [
    "def run_buy_hold(env):\n",
    "    obs, _ = env.reset()\n",
    "    equity = [1.0]\n",
    "\n",
    "    done = False\n",
    "    while not done:\n",
    "        obs, reward, terminated, truncated, info = env.step(1)  # Buy\n",
    "        equity.append(equity[-1] + reward)\n",
    "        done = terminated or truncated\n",
    "\n",
    "    return np.array(equity)\n",
    "\n",
    "\n",
    "env = TradingEnv(max_steps=1000)\n",
    "bh_equity = run_buy_hold(env)\n",
    "\n",
    "bh_returns = compute_returns(bh_equity)\n",
    "\n",
    "bh_sharpe = sharpe_ratio(bh_returns)\n",
    "bh_dd = max_drawdown(bh_equity)\n",
    "\n",
    "print(f\"Buy & Hold Sharpe: {bh_sharpe:.3f}\")\n",
    "print(f\"Buy & Hold Max Drawdown: {bh_dd:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87b4c304-ebba-4800-aab1-f8d90245597b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Sharpe: 0.045\n",
      "Random Max Drawdown: 14.088\n"
     ]
    }
   ],
   "source": [
    "def run_random(env):\n",
    "    obs, _ = env.reset()\n",
    "    equity = [1.0]\n",
    "\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = env.action_space.sample()\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        equity.append(equity[-1] + reward)\n",
    "        done = terminated or truncated\n",
    "\n",
    "    return np.array(equity)\n",
    "\n",
    "\n",
    "env = TradingEnv(max_steps=1000)\n",
    "rand_equity = run_random(env)\n",
    "\n",
    "rand_returns = compute_returns(rand_equity)\n",
    "\n",
    "rand_sharpe = sharpe_ratio(rand_returns)\n",
    "rand_dd = max_drawdown(rand_equity)\n",
    "\n",
    "print(f\"Random Sharpe: {rand_sharpe:.3f}\")\n",
    "print(f\"Random Max Drawdown: {rand_dd:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85775412-d4ca-4287-b9b5-5cd6e9f64902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Agent</th>\n",
       "      <th>Sharpe Ratio</th>\n",
       "      <th>Max Drawdown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RL Agent</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Buy &amp; Hold</td>\n",
       "      <td>0.059898</td>\n",
       "      <td>489.947777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random</td>\n",
       "      <td>0.044724</td>\n",
       "      <td>14.088457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Agent  Sharpe Ratio  Max Drawdown\n",
       "0    RL Agent      0.000000      0.000000\n",
       "1  Buy & Hold      0.059898    489.947777\n",
       "2      Random      0.044724     14.088457"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({\n",
    "    \"Agent\": [\"RL Agent\", \"Buy & Hold\", \"Random\"],\n",
    "    \"Sharpe Ratio\": [rl_sharpe, bh_sharpe, rand_sharpe],\n",
    "    \"Max Drawdown\": [rl_dd, bh_dd, rand_dd]\n",
    "})\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86ef5ed-b0f3-4fee-89d1-92cd297544c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(rl_equity, label=\"RL Agent\")\n",
    "plt.plot(bh_equity, label=\"Buy & Hold\")\n",
    "plt.plot(rand_equity, label=\"Random\")\n",
    "plt.legend()\n",
    "plt.title(\"Equity Curve Comparison\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Portfolio Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44aad4cc-026c-42ac-a587-6254947a284a",
   "metadata": {},
   "source": [
    "Day 10: Alpha Benchmarking — The Alpha Test\n",
    "Objective\n",
    "The goal of Day 10 is to determine whether the trained RL agent delivers statistical or economic value relative to simple baseline strategies under identical market conditions.\n",
    "\n",
    "This is framed as a null-hypothesis test:\n",
    "\n",
    "Is the agent genuinely intelligent, or merely unchallenged?\n",
    "\n",
    "Experimental Setup\n",
    "All agents were evaluated under identical conditions:\n",
    "\n",
    "Same trading environment\n",
    "Same episode length\n",
    "Same reward structure\n",
    "Same execution mechanics\n",
    "No learning during evaluation (policies frozen)\n",
    "Three agents were benchmarked:\n",
    "\n",
    "RL Agent (trained PPO policy from Day 5)\n",
    "Buy & Hold Agent\n",
    "Random Agent\n",
    "Evaluation Metrics\n",
    "The following risk-adjusted performance metrics were used:\n",
    "\n",
    "Sharpe Ratio\n",
    "[ \\text{Sharpe} = \\frac{\\mu_R}{\\sigma_R} ]\n",
    "\n",
    "Measures return per unit of risk\n",
    "Penalizes volatility\n",
    "Standard industry metric\n",
    "Maximum Drawdown\n",
    "[ \\text{Max DD} = \\max_t \\left( \\frac{\\text{Peak}_t - V_t}{\\text{Peak}_t} \\right) ]\n",
    "\n",
    "Captures worst peak-to-trough loss\n",
    "Critical for capital preservation\n",
    "Results Summary\n",
    "Agent\tSharpe Ratio\tMax Drawdown\n",
    "RL Agent\t0.0000\t0.0000\n",
    "Buy & Hold\t-0.9054\t523.41\n",
    "Random\t0.0175\t476.52\n",
    "Equity Curve Analysis\n",
    "The equity curve comparison reveals:\n",
    "\n",
    "RL Agent maintains a flat equity curve, indicating minimal exposure and effective risk avoidance.\n",
    "Buy & Hold experiences severe drawdowns, reflecting persistent adverse price movement.\n",
    "Random Agent exhibits noisy behavior with large drawdowns, characteristic of uninformed trading.\n",
    "The RL agent avoids catastrophic loss but also fails to generate positive returns.\n",
    "\n",
    "Interpretation\n",
    "Does alpha exist?\n",
    "No.\n",
    "\n",
    "The RL agent does not outperform the Random baseline on a risk-adjusted basis, nor does it generate positive Sharpe ratio.\n",
    "\n",
    "What behavior dominates?\n",
    "The RL agent has learned a capital preservation strategy.\n",
    "It avoids overtrading and exposure but does not exploit profitable structure.\n",
    "This suggests a conservative policy shaped by the reward function.\n",
    "Risk Assessment\n",
    "The RL agent exhibits excellent drawdown control.\n",
    "However, the absence of return indicates over-penalization of risk or insufficient reward signal strength.\n",
    "\n",
    "Conclusion:\n",
    "This benchmark rejects the null hypothesis of alpha generation.\n",
    "\n",
    "While the RL agent demonstrates stability and risk awareness, it does not yet produce economically meaningful returns.\n",
    "\n",
    "This is a valid scientific outcome.\n",
    "\n",
    "The result indicates that further improvements must focus on:\n",
    "\n",
    "Reward shaping\n",
    "Exploration incentives\n",
    "Market structure richness\n",
    "Rather than further hyperparameter tuning.\n",
    "\n",
    "Final Verdict:\n",
    "The agent is safe, but not yet smart.\n",
    "\n",
    "Day 10 establishes a critical baseline for future improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b3c0db-db5e-48f3-bdb5-4898387b202e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
